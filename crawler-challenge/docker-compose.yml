version: '3.8'

services:
  # 1. Infrastructure Services (DB & Cache)
  redis:
    image: redis:7-alpine
    container_name: crawler-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: always

  postgres:
    image: postgres:15
    container_name: crawler-postgres
    environment:
      POSTGRES_DB: crawler_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres # 개발용이므로 단순화, 보안 필요시 변경
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: always
    # DB가 완전히 켜졌는지 확인하는 헬스체크 (크롤러들의 안정적 접속을 위해)
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 5s
      timeout: 5s
      retries: 5
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: crawler-postgres-exporter
    ports:
      - "9187:9187" # Prometheus가 긁어갈 포트
    environment:
      DATA_SOURCE_NAME: "postgresql://postgres:postgres@postgres:5432/crawler_db?sslmode=disable"
      PG_EXPORTER_EXTEND_QUERY_PATH: "/queries.yaml"
    volumes:
      - ./docker/queries.yaml:/queries.yaml:ro
    depends_on:
      - postgres
    restart: always

  # 2. Crawler Services
  crawler-master:
    ports:
      - "8000:8000"
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-master
    # 실제 실행 명령어 (테스트 끝났으면 주석 해제)
    command: python runners/sharded_master.py --count 100000 --workers 8
    environment:
      # 같은 도커 네트워크라 서비스명(redis, postgres)으로 접속 가능
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      # AI 리포트 생성용 (Prometheus는 Docker 호스트에서 접근)
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - PROMETHEUS_URL=http://100.105.22.101:9090
    volumes:
      - ./logs:/app/logs
      - ./docs/reports:/app/docs/reports
      - ./.env:/app/.env:ro
    depends_on:
      redis:
        condition: service_started
      postgres:
        condition: service_healthy # DB가 쿼리 받을 준비가 되면 실행
    restart: on-failure

  crawler-worker-1:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-1
    command: python runners/sharded_worker.py --worker-id 1
    ports:
      - "8001:8001"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-2:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-2
    command: python runners/sharded_worker.py --worker-id 2
    ports:
      - "8002:8002"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-3:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-3
    command: python runners/sharded_worker.py --worker-id 3
    ports:
      - "8003:8003"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-4:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-4
    command: python runners/sharded_worker.py --worker-id 4
    ports:
      - "8004:8004"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-5:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-5
    command: python runners/sharded_worker.py --worker-id 5
    ports:
      - "8005:8005"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-6:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-6
    command: python runners/sharded_worker.py --worker-id 6
    ports:
      - "8006:8006"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-7:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-7
    command: python runners/sharded_worker.py --worker-id 7
    ports:
      - "8007:8007"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

  crawler-worker-8:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: crawler-worker-8
    command: python runners/sharded_worker.py --worker-id 8
    ports:
      - "8008:8008"
    environment:
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - ./logs:/app/logs
    depends_on:
      crawler-master:
        condition: service_started
    restart: always

volumes:
  redis_data:
  postgres_data:
