#!/usr/bin/env python3
"""
ì›ê²© í¬ë¡¤ë§ ì œì–´ CLI
Windows ë°ìŠ¤í¬í†±ì—ì„œ MacBook ì„œë²„ì˜ í¬ë¡¤ë§ì„ ì œì–´

Usage:
    python crawler_cli.py start --workers 4 --urls 10000
    python crawler_cli.py status
    python crawler_cli.py stop
    python crawler_cli.py watch
"""

import argparse
import requests
import sys
import time
import os

# ============================================
# ì„¤ì •
# ============================================

# MacBook Tailscale IP (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
SERVER_URL = os.environ.get("CRAWLER_SERVER", "http://100.125.119.99:8080")


# ============================================
# ìœ í‹¸ë¦¬í‹°
# ============================================
def print_colored(text: str, color: str = "white"):
    colors = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "cyan": "\033[96m",
        "white": "\033[97m",
        "reset": "\033[0m"
    }
    print(f"{colors.get(color, '')}{text}{colors['reset']}")


def format_time(seconds: float) -> str:
    if seconds is None:
        return "N/A"
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes}ë¶„ {secs}ì´ˆ"


# ============================================
# ëª…ë ¹ì–´ êµ¬í˜„
# ============================================
def cmd_start(args):
    """í¬ë¡¤ë§ ì‹œì‘"""
    print_colored("\nğŸš€ í¬ë¡¤ë§ ì‹œì‘ ìš”ì²­", "cyan")
    print(f"   ì„œë²„: {SERVER_URL}")
    print(f"   Workers: {args.workers}")
    print(f"   URLs: {args.urls:,}")

    try:
        response = requests.post(
            f"{SERVER_URL}/crawl/start",
            json={
                "workers": args.workers,
                "url_count": args.urls
            },
            timeout=10
        )

        if response.status_code == 200:
            print_colored("\nâœ… í¬ë¡¤ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!", "green")
            print("   ìƒíƒœ í™•ì¸: python crawler_cli.py status")
            print("   ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§: python crawler_cli.py watch")
        else:
            error = response.json().get('detail', 'Unknown error')
            print_colored(f"\nâŒ ì—ëŸ¬: {error}", "red")

    except requests.exceptions.ConnectionError:
        print_colored(f"\nâŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SERVER_URL}", "red")
        print("   - Tailscale ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
        print("   - ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
    except Exception as e:
        print_colored(f"\nâŒ ì—ëŸ¬: {e}", "red")


def cmd_status(args):
    """í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ"""
    try:
        response = requests.get(f"{SERVER_URL}/crawl/status", timeout=5)
        data = response.json()

        print("\n" + "=" * 50)
        print_colored("ğŸ“Š í¬ë¡¤ë§ ìƒíƒœ", "cyan")
        print("=" * 50)

        # ìƒíƒœ ì•„ì´ì½˜
        if data["is_running"]:
            print_colored("ìƒíƒœ: ğŸŸ¢ ì‹¤í–‰ ì¤‘", "green")
        else:
            print_colored("ìƒíƒœ: ğŸŸ¡ ëŒ€ê¸° ì¤‘", "yellow")

        print(f"Workers: {data['workers']}")
        print(f"ëª©í‘œ URL: {data['target_urls']:,}")
        print(f"ì²˜ë¦¬ ì™„ë£Œ: {data['processed_urls']:,}")
        print(f"ì„±ê³µ: {data['success_count']:,}")
        print(f"ì‹¤íŒ¨: {data['fail_count']:,}")
        print(f"ì§„í–‰ë¥ : {data['progress_percent']}%")
        print(f"ê²½ê³¼ ì‹œê°„: {format_time(data['elapsed_seconds'])}")

        if data['pages_per_second']:
            print(f"ì²˜ë¦¬ ì†ë„: {data['pages_per_second']} pages/sec")

        print("=" * 50)

    except requests.exceptions.ConnectionError:
        print_colored(f"\nâŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SERVER_URL}", "red")
    except Exception as e:
        print_colored(f"\nâŒ ì—ëŸ¬: {e}", "red")


def cmd_stop(args):
    """í¬ë¡¤ë§ ì¤‘ì§€"""
    print_colored("\nğŸ›‘ í¬ë¡¤ë§ ì¤‘ì§€ ìš”ì²­...", "yellow")

    try:
        response = requests.post(f"{SERVER_URL}/crawl/stop", timeout=10)

        if response.status_code == 200:
            data = response.json()
            print_colored("âœ… í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.", "green")
            print(f"   ì²˜ë¦¬: {data['summary']['processed']:,}")
            print(f"   ì„±ê³µ: {data['summary']['success']:,}")
            print(f"   ì‹¤íŒ¨: {data['summary']['failed']:,}")
        else:
            error = response.json().get('detail', 'Unknown error')
            print_colored(f"âŒ ì—ëŸ¬: {error}", "red")

    except requests.exceptions.ConnectionError:
        print_colored(f"\nâŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SERVER_URL}", "red")
    except Exception as e:
        print_colored(f"\nâŒ ì—ëŸ¬: {e}", "red")


def cmd_watch(args):
    """ì‹¤ì‹œê°„ ìƒíƒœ ëª¨ë‹ˆí„°ë§"""
    print_colored("\nğŸ‘€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)", "cyan")
    print(f"   ê°±ì‹  ì£¼ê¸°: {args.interval}ì´ˆ\n")

    try:
        while True:
            # í™”ë©´ í´ë¦¬ì–´ (Windows/Unix í˜¸í™˜)
            os.system('cls' if os.name == 'nt' else 'clear')

            print_colored("ğŸ‘€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (Ctrl+Cë¡œ ì¢…ë£Œ)\n", "cyan")

            try:
                response = requests.get(f"{SERVER_URL}/crawl/status", timeout=5)
                data = response.json()

                # ìƒíƒœ í‘œì‹œ
                status = "ğŸŸ¢ ì‹¤í–‰ ì¤‘" if data["is_running"] else "ğŸŸ¡ ëŒ€ê¸° ì¤‘"
                print(f"ìƒíƒœ: {status}")
                print(f"ì§„í–‰ë¥ : {data['progress_percent']}% ({data['processed_urls']:,}/{data['target_urls']:,})")
                print(f"ì„±ê³µ/ì‹¤íŒ¨: {data['success_count']:,} / {data['fail_count']:,}")
                print(f"ê²½ê³¼: {format_time(data['elapsed_seconds'])}")

                if data['pages_per_second']:
                    print(f"ì†ë„: {data['pages_per_second']} pages/sec")

                # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
                if data['target_urls'] > 0:
                    progress = int(data['progress_percent'] / 2)  # 50ì¹¸ ê¸°ì¤€
                    bar = "â–ˆ" * progress + "â–‘" * (50 - progress)
                    print(f"\n[{bar}] {data['progress_percent']}%")

            except requests.exceptions.ConnectionError:
                print_colored("âŒ ì—°ê²° ëŠê¹€ - ì¬ì‹œë„ ì¤‘...", "red")

            time.sleep(args.interval)

    except KeyboardInterrupt:
        print("\n\nëª¨ë‹ˆí„°ë§ ì¢…ë£Œ")


def cmd_health(args):
    """ì„œë²„ í—¬ìŠ¤ì²´í¬"""
    try:
        response = requests.get(f"{SERVER_URL}/health", timeout=5)
        if response.status_code == 200:
            print_colored("âœ… ì„œë²„ ì •ìƒ", "green")
            print(f"   URL: {SERVER_URL}")
        else:
            print_colored("âš ï¸ ì„œë²„ ì‘ë‹µ ì´ìƒ", "yellow")
    except requests.exceptions.ConnectionError:
        print_colored(f"âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {SERVER_URL}", "red")


# ============================================
# ë©”ì¸
# ============================================
def main():
    parser = argparse.ArgumentParser(
        description="ì›ê²© í¬ë¡¤ë§ ì œì–´ CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python crawler_cli.py health              # ì„œë²„ ìƒíƒœ í™•ì¸
  python crawler_cli.py start -w 4 -u 10000 # í¬ë¡¤ë§ ì‹œì‘
  python crawler_cli.py status              # ìƒíƒœ ì¡°íšŒ
  python crawler_cli.py watch               # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
  python crawler_cli.py stop                # í¬ë¡¤ë§ ì¤‘ì§€

Environment:
  CRAWLER_SERVER  ì„œë²„ ì£¼ì†Œ (ê¸°ë³¸ê°’: http://100.125.119.99:8080)
        """
    )

    parser.add_argument(
        "--server", "-s",
        default=SERVER_URL,
        help="ì„œë²„ ì£¼ì†Œ"
    )

    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")

    # health
    subparsers.add_parser("health", help="ì„œë²„ í—¬ìŠ¤ì²´í¬")

    # start
    start_parser = subparsers.add_parser("start", help="í¬ë¡¤ë§ ì‹œì‘")
    start_parser.add_argument("--workers", "-w", type=int, default=4)
    start_parser.add_argument("--urls", "-u", type=int, default=10000)

    # status
    subparsers.add_parser("status", help="ìƒíƒœ ì¡°íšŒ")

    # stop
    subparsers.add_parser("stop", help="í¬ë¡¤ë§ ì¤‘ì§€")

    # watch
    watch_parser = subparsers.add_parser("watch", help="ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    watch_parser.add_argument("--interval", "-i", type=int, default=3)

    args = parser.parse_args()

    # ì„œë²„ ì£¼ì†Œ ì—…ë°ì´íŠ¸
    global SERVER_URL
    SERVER_URL = args.server

    # ëª…ë ¹ì–´ ì‹¤í–‰
    if args.command == "health":
        cmd_health(args)
    elif args.command == "start":
        cmd_start(args)
    elif args.command == "status":
        cmd_status(args)
    elif args.command == "stop":
        cmd_stop(args)
    elif args.command == "watch":
        cmd_watch(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
